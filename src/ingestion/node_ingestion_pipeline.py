# ocr ë¼ì´ë¸ŒëŸ¬ë¦¬ ì“´ë‹¤ë©´ (ì´ì§„ì•„) ê²€ìƒ‰í•˜ê¸°
# --------------------------------------------------------------
# node_ingestion_pipeline.py
# íŒŒì¼ ì—…ë¡œë“œ í›„ ì „ì²´ ingestion íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
# - íŒŒì¼ íƒ€ì… íŒë³„ â†’ PDF ë³€í™˜ â†’ OCR â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ í´ë Œì§•/LLM ì •ì œ
# --------------------------------------------------------------

# import os
# import tkinter as tk
# from tkinter import filedialog
from typing import List


from src.utils.state import State
from src.ingestion.file_classifier import classify_file
# from src.ingestion.pdf_converter import doc_to_pdf, images_to_pdf
from src.ingestion.doc_parser import extract_pdf_text #, extract_ppt_text
# from src.ingestion.ocr_image_runner import pdf_to_images, run_ocr
from src.utils.text_utils import preprocess_text
from src.utils.file_utils import create_output_folder
from src.utils.logger import log, user_log 
from src.ingestion.llm_clean_data_pll import llm_text_from_images #,llm_clean_pii,


# -------------------------------
# OCR ì—¬ë¶€ í™•ì¸ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
# -------------------------------
def check_do_ocr(pdf_path: str, state: dict):
    """
    PDF í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì—†ëŠ” ê²ƒ í™•ì¸ í›„ OCR (í´ë Œì§•+LLM í•˜ê¸° ì „)
    """
    log(f"[PDF íŒŒì„œ] í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì¶”ì¶œ ì‹œë„: {pdf_path}")
    parsed_pages = extract_pdf_text(pdf_path)  # list[str]

    # PDF í…ìŠ¤íŠ¸ ë ˆì´ì–´ê°€ ìˆëŠ” ê²½ìš°(list ì¤‘ í•˜ë‚˜ë¼ë„ text ì¡´ì¬)
    all_text = "\n".join(parsed_pages).strip()
    if len(all_text) >= 10:
        log("[PDF íŒŒì„œ] í…ìŠ¤íŠ¸ ë ˆì´ì–´ê°€ ê°ì§€ë˜ì–´ OCR ìƒëµ")
        state["raw_txt"] = parsed_pages  # state ì €ì¥
        return parsed_pages
    


    # OCR ìˆ˜í–‰
    log("[OCR] í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì—†ìŒ â†’ OCR ìˆ˜í–‰ ì‹œì‘")
    user_log("ë¬¸ì„œì— í…ìŠ¤íŠ¸ ì •ë³´ê°€ ì—†ì–´ ì´ë¯¸ì§€ ê¸°ë°˜ OCRì„ ì§„í–‰í•©ë‹ˆë‹¤. ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš” ğŸ˜Š", step="ocr")

    #(ì´ì§„ì•„) ì£¼ì„í•˜ê¸°
    ocr_pages = llm_text_from_images([pdf_path])

    #(ì´ì§„ì•„) ì£¼ì„í•´ì œ
    # images = pdf_to_images(pdf_path)
    # log(f"[OCR] PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ (ì´ {len(images)}í˜ì´ì§€)")
    # ocr_pages = run_ocr(images)  # list[str]
    # log("[OCR] OCR ì™„ë£Œ")

    state["raw_txt"] = ocr_pages  
    return ocr_pages



# -------------------------------
# ë©”ì¸ Ingestion íŒŒì´í”„ë¼ì¸
# -------------------------------
def node_ingestion_pipeline(state: dict) -> State:
    """
    ë¬¸ì„œ íŒŒì¼ í™•ì¥ì íŒë³„ í›„ í™•ì¥ìë³„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    â†’ í´ë Œì§• + LLM ì •ì œê¹Œì§€ ìˆ˜í–‰
    ê²°ê³¼ëŠ” state["raw_txt"] (List[str])ì— ì €ì¥
    """
    # ì¶œë ¥ í´ë” ìƒì„±
    output_dir = create_output_folder()
    state["output_dir"] = output_dir
    log(f"[íŒŒì´í”„ë¼ì¸] output ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")
 
    # ì…ë ¥ íŒŒì¼ì´ ì—¬ëŸ¬ ê°œì¼ ê²½ìš° â†’ ì²« ë²ˆì§¸ íŒŒì¼ë¡œ íƒ€ì… íŒë³„
    first_file = state["input_paths"][0]
    log(f"[íŒŒì´í”„ë¼ì¸] ì…ë ¥ íŒŒì¼ ê²½ë¡œ: {first_file}")

    # ì´ë¯¸ì§€ ì—¬ëŸ¬ ì¥ ì²˜ë¦¬ìš© ì „ì²´ ë¦¬ìŠ¤íŠ¸
    input_paths = state["input_paths"] 


    # -------------------------------
    # 1) íŒŒì¼ íƒ€ì… íŒë³„
    # -------------------------------
    file_type = classify_file(first_file)
    log(f"[íŒŒì´í”„ë¼ì¸] íŒë³„ëœ íŒŒì¼ íƒ€ì…: {file_type}")

    txt_pages: List[str] = []

    # -------------------------------
    # 2) ì´ë¯¸ì§€ : ì—¬ëŸ¬ ì¥ PDF í†µí•© í›„ OCR ì§„í–‰
    # -------------------------------
    if file_type == "image":
        #(ì´ì§„ì•„) ì•„ë˜ ë‘ë¬¸ì¥ ì£¼ì„ì²˜ë¦¬
        txt_pages = llm_text_from_images(input_paths)
        state["raw_txt"] = txt_pages
        #(ì´ì§„ì•„) ì£¼ì„í•´ì œ
        # pdf_path = images_to_pdf(
        #     input_paths,
        #     os.path.join(output_dir, "images_to_pdf.pdf"),
        # )
        # log(f"[ë³€í™˜] ì´ë¯¸ì§€ -> PDF ë³€í™˜ ì™„ë£Œ: {pdf_path}")
        # txt_pages = check_do_ocr(pdf_path,state)
        

    # -------------------------------
    # 3) TXT : í´ë Œì§• í›„ ë°”ë¡œ ì‚¬ìš©
    # -------------------------------
    # elif file_type == "text":
    #     user_log("í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ íŒë‹¨ë˜ì–´, ë‚´ìš©ì„ ë°”ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.", step="read_text")
    #     with open(first_file, "r", encoding="utf-8") as f:
    #         raw_txt = f.read()
    #     txt_pages = [raw_txt]
    #     log("[í…ìŠ¤íŠ¸] TXT íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì½ê¸° ì™„ë£Œ")

    # -------------------------------
    # 4) PPT : ë³„ë„ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    # -------------------------------
    # elif file_type == "ppt":
    #     user_log("PPT ë¬¸ì„œë¡œ íŒë‹¨ë˜ì–´, ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.", step="ppt_parse")
    #     full_txt = extract_ppt_text(first_file)
    #     txt_pages = [full_txt]
    #     log("[PPT] PPT í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")

    # -------------------------------
    # 5) Word : PDF ë³€í™˜ í›„ ì²˜ë¦¬ (HWPëŠ” í˜„ì¬ ë³´ë¥˜)
    # -------------------------------
    # elif file_type == "word":
    #     user_log("Word ë¬¸ì„œë¡œ íŒë‹¨ë˜ì–´, PDFë¡œ ë³€í™˜ í›„ ì²˜ë¦¬í•©ë‹ˆë‹¤.", step="word_convert")
    #     pdf_path = doc_to_pdf(
    #         first_file,
    #         os.path.join(output_dir, "doc_to_pdf.pdf"),
    #     )
    #     log(f"[ë³€í™˜] Word â†’ PDF ë³€í™˜ ì™„ë£Œ: {pdf_path}")
    #     txt_pages = check_do_ocr(pdf_path,state)

    # -------------------------------
    # 6) PDF : í…ìŠ¤íŠ¸ ë ˆì´ì–´ í™•ì¸ í›„ í•„ìš” ì‹œ OCR
    # -------------------------------
    elif file_type == "pdf":
        user_log("PDF ë¬¸ì„œë¡œ íŒë‹¨ë˜ì–´, í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.", step="pdf_parse")
        txt_pages = check_do_ocr(first_file,state)

    else:
        user_log("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë¬¸ì„œë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.", step="error")
        log(f"[ì—ëŸ¬] ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…: {file_type}", level="error")
        state["raw_txt"] = []
        return state

    # -------------------------------
    # 7) í´ë Œì§• + LLM ì •ì œ
    # -------------------------------
    user_log("ë¬¸ì„œ ë‚´ìš©ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš” âœ¨", step="clean_llm")
    log("[í´ë Œì§•] preprocess_text + llm_cleaner ì‹œì‘")
    #(ì´ì§„ì•„) ë‘ì¤„ ì£¼ì„í•„ìš”
    clean_txt_pages: List[str] = [
    preprocess_text(t or "") for t in txt_pages]

    # (ì´ì§„ì•„) ì£¼ì„í•´ì œ
    # clean_txt_pages: List[str] = [
    #     llm_clean_pii(preprocess_text(t or "")) for t in txt_pages
    # ]

    log("[í´ë Œì§•] ëª¨ë“  í˜ì´ì§€ í´ë Œì§• + LLM ì •ì œ ì™„ë£Œ")

    state["refined_txt"] = clean_txt_pages
    user_log("ë¬¸ì„œ ë¶„ì„ ì¤€ë¹„ê°€ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤", step="done")
    log("[íŒŒì´í”„ë¼ì¸] node_ingestion_pipeline ì™„ë£Œ")

    return state
